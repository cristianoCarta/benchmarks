{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "import h5py\n",
    "from src.benchmarkers import *\n",
    "from src.benchmarkersV2 import *\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_name(name):\n",
    "    print(name)\n",
    "\n",
    "#with h5py.File(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\outputs\\v2\\32\\ds_10_core.h5\", \"r\") as file:\n",
    "#table = pq.read_table(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\outputs\\v2\\235\\ds_100.parquet\")\n",
    "#with pa.memory_map(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\outputs\\v2\\235\\ds_100_stream.arrows\", 'rb') as source:\n",
    "#        table = pa.ipc.open_stream(source).read_all()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = [10,100,200,300,500]\n",
    "N = [10]\n",
    "#dimensions = [32,64,125,192]\n",
    "dimensions = [235]\n",
    "selected_label = 10\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in tqdm(N):\n",
    "#    for dim in dimensions:\n",
    "#        generator.create_dataset(item,f\"outputs/v2/{dim}/ds_{item}\",dim)\n",
    "#        generator.create_arrow_file(f\"outputs/v2/{dim}/ds_{item}\")\n",
    "#        generator.create_arrow_stream(f\"outputs/v2/{dim}/ds_{item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader a dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = \"\"\n",
    "\n",
    "classes = sorted(entry.name for entry in os.scandir(root_path) if entry.is_dir())\n",
    "\n",
    "if not classes:\n",
    "    raise FileNotFoundError(f\"Couldn't find any class folder in {root_path}.\")\n",
    "\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "directory = os.path.expanduser(root_path)\n",
    "\n",
    "files = []\n",
    "\n",
    "for target_class in sorted(class_to_idx.keys()):\n",
    "    class_index = class_to_idx[target_class]\n",
    "    target_dir = os.path.join(directory, target_class)\n",
    "    if not os.path.isdir(target_dir):\n",
    "        continue\n",
    "    for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n",
    "        for fname in sorted(fnames):\n",
    "            path = os.path.join(root, fname)\n",
    "            Y = {\n",
    "                \"label\": class_index\n",
    "            }\n",
    "            X = {\n",
    "                \"path\": path\n",
    "            }\n",
    "            #Open the image\n",
    "            #Save the image in the sample structure of our framework\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks], dtype=float).reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferenza con salvataggio dei tempi (classificazione)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
