{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from src.benchmarkers import *\n",
    "from src.benchmarkersV2 import *\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from io import BytesIO\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image \n",
    "#    |_____text\n",
    "#    |_____label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"imagenette/imagenette2/val\"\n",
    "save_path = \"imagenette/imagenette2/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"imagenette/imagenette2/val\"\n",
    "save_path = \"imagenette/imagenette2/output\"\n",
    "\n",
    "classes = sorted(entry.name for entry in os.scandir(root_path) if entry.is_dir())\n",
    "\n",
    "if not classes:\n",
    "    raise FileNotFoundError(f\"Couldn't find any class folder in {root_path}.\")\n",
    "\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "directory = os.path.expanduser(root_path)\n",
    "\n",
    "output = []\n",
    "restart = 0 \n",
    "\n",
    "#with h5py.File(f\"{save_path}/ds.h5\", 'w') as f:\n",
    "for j, target_class in enumerate(sorted(class_to_idx.keys())):\n",
    "    class_index = class_to_idx[target_class]\n",
    "    target_dir = os.path.join(directory, target_class)\n",
    "    if not os.path.isdir(target_dir):\n",
    "        continue\n",
    "    for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)): \n",
    "        for i, fname in enumerate(sorted(fnames)):\n",
    "            path = os.path.join(root, fname)\n",
    "            label_index = class_index\n",
    "            text = \"an image of a \" + target_class\n",
    "            image = Image.open(path)\n",
    "            buffer = BytesIO()\n",
    "            image.save(buffer,format=\"JPEG\")\n",
    "            jpeg_byte_array = buffer.getvalue()\n",
    "            \n",
    "            sample = {\n",
    "                \"image_feature\":[\n",
    "                    {\n",
    "                        \"image\" : jpeg_byte_array,\n",
    "                        \"class_feature\":[\n",
    "                            {\n",
    "                                \"label\" : class_index\n",
    "                            }\n",
    "                        ],\n",
    "                        \"text_feature\" : [\n",
    "                            {\n",
    "                                \"text\" : text\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            output.append(sample)\n",
    "\n",
    "                #example = f.create_group(f'example_{restart}')\n",
    "                #image_feature = example.create_group('image_feature')\n",
    "#\n",
    "                #\n",
    "                #restart += 1\n",
    "                #\n",
    "                ## Image 1\n",
    "                #image1 = image_feature.create_group('image1')\n",
    "                #im1ds = image1.create_dataset('image', data=np.array(image))  \n",
    "                #im1ds.attrs[\"type\"] = \"image\"\n",
    "                #im1ds.attrs[\"label\"] = class_index\n",
    "#\n",
    "                ## Text feature\n",
    "                #text_feature = image1.create_group('text_feature')\n",
    "                #txtds = text_feature.create_dataset('text', data=text)\n",
    "                #txtds.attrs[\"type\"] = \"text\"\n",
    "\n",
    "table = pa.Table.from_pylist(output)\n",
    "pq.write_table(table, save_path+\"/ds.parquet\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\imagenette\\imagenette2\\output\\ds.parquet\")\n",
    "batches = table.to_batches()\n",
    "with pa.OSFile(f\"{save_path}/ds_stream.arrows\", 'wb') as sink:  \n",
    "    with pa.ipc.new_stream(sink, batches[0].schema) as writer:  \n",
    "        for batch in batches:\n",
    "            writer.write_batch(batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pa.OSFile(f\"{save_path}/ds_file.arrow\", 'wb') as sink:  \n",
    "    with pa.ipc.new_file(sink, batches[0].schema) as writer:  \n",
    "        for batch in batches:\n",
    "            writer.write_batch(batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\imagenette\\imagenette2\\output\\ds.h5\",\"r\") as f:\n",
    "    print(len(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_iterations(stringa : str,file : h5py.Dataset):\n",
    "    i = 0\n",
    "    j = 1\n",
    "    go = True\n",
    "    while go:\n",
    "        dataset = file.get(stringa.replace(\"REPLACE\",str(j)))\n",
    "        if dataset:\n",
    "            j = j + 1\n",
    "            i = i + 1\n",
    "        else:\n",
    "            go = False\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, path: str , driver :str):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.f = h5py.File(self.path,\"r\",driver=driver)\n",
    "        self.driver = driver\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.f)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        example = self.f[f\"example_{idx}\"]\n",
    "        image_feature = example[\"image_feature\"]\n",
    "        images = []\n",
    "        labels = []\n",
    "        texts = []\n",
    "        for name , child in image_feature.items():\n",
    "            if isinstance(child,h5py.Group):\n",
    "                ds = child[\"image\"]\n",
    "                if (\"type\" in ds.attrs) and ds.attrs[\"type\"] == \"image\":\n",
    "                    imagepil = Image.fromarray(ds[:])\n",
    "                    transform = transforms.Compose([\n",
    "                    transforms.Resize((500, 500)),  # Resize to a square shape\n",
    "                    transforms.ToTensor(),          # Convert image to tensor\n",
    "                    ])\n",
    "                    images.append(transform(imagepil))\n",
    "                    labels.append(ds.attrs[\"label\"])\n",
    "                    for name , child2 in child.items():\n",
    "                        if isinstance(child2,h5py.Group): \n",
    "                            ds2 = child2[\"text\"]\n",
    "                            if (\"type\" in ds2.attrs) and ds2.attrs[\"type\"] == \"text\":\n",
    "                                texts.append(ds2[()].decode(\"utf-8\"))\n",
    "\n",
    "        sample = {\n",
    "            \"images\" : images,\n",
    "            \"texts\" : texts,\n",
    "            \"labels\" : labels\n",
    "        }\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def close(self):\n",
    "        self.f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_ds = HDF5Dataset(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\imagenette\\imagenette2\\output\\ds.h5\",\"core\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 500, 500])\n"
     ]
    }
   ],
   "source": [
    "sample = hdf5_ds[3700]\n",
    "print(sample[\"images\"][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrowDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path :str, mode : str):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        if mode == \"stream_memorymap\":\n",
    "            with pa.memory_map(self.path, 'rb') as source:\n",
    "                table = pa.ipc.open_stream(source).read_all()\n",
    "                self.table = table\n",
    "        \n",
    "        elif mode == \"file_memorymap\":\n",
    "            with pa.memory_map(self.path, 'rb') as source:\n",
    "                table = pa.ipc.open_file(source).read_all()\n",
    "                self.table = table\n",
    "        \n",
    "        elif mode == \"stream_no_memorymap\":\n",
    "            with pa.OSFile(self.path, 'rb') as source:\n",
    "                table = pa.ipc.open_stream(source).read_all()\n",
    "                self.table = table\n",
    "\n",
    "        elif mode == \"file_no_memorymap\":\n",
    "            with pa.OSFile(self.path, 'rb') as source:\n",
    "                table = pa.ipc.open_file(source).read_all()\n",
    "                self.table = table\n",
    "\n",
    "        elif mode == \"parquet\":\n",
    "            table = pq.read_table(self.path)\n",
    "            self.table = table\n",
    "\n",
    "        else:\n",
    "            raise NameError(\"mode str is not implemented. Choose between: stream_memorymap, file_memorymap, stream_no_memorymap, file_no_memorymap, parquet\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table)\n",
    "                            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        images = self.table.column(\"image_feature\")[idx].values.field(\"image\").to_pylist()\n",
    "        labels = self.table.column(\"image_feature\")[idx].values.field(\"class_feature\")[0].values.field(\"label\").to_pylist()\n",
    "        texts =  self.table.column(\"image_feature\")[idx].values.field(\"text_feature\")[0].values.field(\"text\").to_pylist()\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "                    transforms.Resize((500, 500)),  # Resize to a square shape\n",
    "                    transforms.ToTensor(),          # Convert image to tensor\n",
    "                    ])\n",
    "\n",
    "        images = [transform(Image.open(BytesIO(item))) for item in images]\n",
    "\n",
    "        sample = {\n",
    "            \"images\" : images,\n",
    "            \"texts\" : texts,\n",
    "            \"labels\" : labels\n",
    "        }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_ds = ArrowDataset(r\"C:\\Users\\Cristiano Lavoro\\Desktop\\benchmarks\\imagenette\\imagenette2\\output\\ds_file.arrow\",\"file_memorymap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = arrow_ds[0][\"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet classification benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP zero shot classification benchmark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
